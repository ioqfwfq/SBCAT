{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcf49a1",
   "metadata": {},
   "source": [
    "# Single-Session vmPFC \u03b8 SFC & Hipp \u03b3\u2194vmPFC \u03b8 ir-PAC\n",
    "Working spec for a one-session pipeline that quantifies hippocampal spike-to-vmPFC theta phase locking and hippocampal gamma amplitude coupling to vmPFC theta phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137eea78",
   "metadata": {},
   "source": [
    "## Notebook Roadmap\n",
    "1. Configure session, storage paths, and analysis parameters.\n",
    "2. Load NWB session data through a common adapter that surfaces canonical tables/arrays.\n",
    "3. Preprocess LFPs (vmPFC \u03b8 phase, hippocampal \u03b3 amplitude) with optional CAR plus Hilbert transforms.\n",
    "4. Build hippocampal unit \u00d7 vmPFC channel pairs (hemisphere-aware).\n",
    "5. Compute vmPFC \u03b8 spike-field coherence with spike-count balancing and jittered surrogate z-scores.\n",
    "6. Compute hippocampal \u03b3 \u2194 vmPFC \u03b8 inter-regional PAC with trial-count balancing, shuffle surrogates, and optional lag sweeps.\n",
    "7. Aggregate per-pair metrics into session-level stats/visuals.\n",
    "8. Emit QC figures, tables, and summaries into a structured output directory.\n",
    "9. Append runtime/context metadata for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb3570",
   "metadata": {},
   "source": [
    "## Inputs & Interface Contract\n",
    "All downstream analysis blocks expect the following canonical objects (regardless of whether they were pulled directly from NWB):\n",
    "\n",
    "- **Events / Trials** \u2013 `trial_table`: DataFrame with `trial_id`, `condition_label`, `rt`, `maint_onset_time` (absolute seconds), `is_correct`, plus any auxiliary columns. Conditioning (e.g., `use_only_correct`, `conditions = ['L1','L3']`) is enforced during adapter loading.\n",
    "- **Spikes** \u2013 `spike_times_by_unit`: dict mapping `unit_id \u2192 np.ndarray` of spike times (seconds). `unit_meta`: DataFrame with `unit_id`, anatomical `area` labels (e.g., `hipp`) and `hemisphere` tags, ideally with the source electrode/channel index.\n",
    "- **LFP** \u2013 `lfp_by_channel`: dict `chan_id \u2192 np.ndarray`, along with `lfp_fs` (Hz), `lfp_start_time` (absolute seconds), and `channel_meta` describing each channel's area, hemisphere, bad-channel flags, and reference metadata. These support CAR/bipolar re-referencing before bandpass/Hilbert steps.\n",
    "- **Session meta** \u2013 lightweight dict containing `session_id`, patient/subject identifiers, session date, and the reference scheme (if available).\n",
    "\n",
    "The adapter defined in `nwb_analysis.cfc.prepare_session_structures` enforces this contract whether data are read from NWB, so the core analysis can focus on: (1) extracting [\u22120.5, +3.0] s windows around maintenance, (2) analyzing the [0, 2.5] s theta/gamma content, (3) equalizing spikes/trials per condition, and (4) computing surrogate-based z-scores (spike jitter for SFC, trial shuffle for PAC with optional lag sweeps).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb611e4",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from nwb_analysis import get_subject_files\n",
    "from nwb_analysis.cfc import (\n",
    "    prepare_session_structures,\n",
    "    compute_vmPFC_theta_phase,\n",
    "    compute_hipp_gamma_envelope,\n",
    "    compute_irpac,\n",
    "    run_session_stats,\n",
    "    plot_session_summary,\n",
    "    save_session_outputs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8b07f",
   "metadata": {},
   "source": [
    "## 2. Config & Session Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5755b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session + storage config\n",
    "DATA_DIR = Path('/Users/jundazhu/SBCAT/000673')\n",
    "SESSION_ID = 'SBCAT_Example_001'  # can be partial stem or left as example\n",
    "SESSION_PATH_OVERRIDE = None      # Path('/absolute/path/to/sub-5_ses-1_ecephys+image.nwb') to skip globbing\n",
    "OUT_DIR = Path('outputs')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "USE_ONLY_CORRECT = True\n",
    "\n",
    "SESSION_OUT_DIR = OUT_DIR / SESSION_ID / 'sfc_irpac_single_session'\n",
    "SESSION_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONDITIONS = ['L1', 'L3']\n",
    "EPOCH_ANALYZE = (0.0, 2.5)       # s window used for analyses relative to maintenance onset\n",
    "THETA_BAND = (3.0, 7.0)\n",
    "GAMMA_BAND = (70.0, 140.0)\n",
    "LOW_GAMMA_BAND = (30.0, 55.0)    # optional second ROI; apply multiplicity corrections if used\n",
    "CAR_MODE = 'hemisphere'\n",
    "MIN_TRIALS_PER_COND = 20\n",
    "PAC_SURR_N = 500\n",
    "REPEATS_EQ = 200\n",
    "LAG_GRID = np.arange(-0.150, 0.155, 0.005)  # seconds\n",
    "EXCLUDE_LAG_S = (0.010, 0.020)              # ignore central lags when reporting lag-swept PAC\n",
    "PEAK_TO_PEAK_THRESH = 3000.0  # \u00b5V; set to None to skip automatic rejection\n",
    "\n",
    "ANALYSIS_PARAMS = {\n",
    "    'conditions': CONDITIONS,\n",
    "    'epoch_analyze': EPOCH_ANALYZE,\n",
    "    'theta_band': THETA_BAND,\n",
    "    'gamma_band': GAMMA_BAND,\n",
    "    'low_gamma_band': LOW_GAMMA_BAND,\n",
    "    'car_mode': CAR_MODE,\n",
    "    'min_trials': MIN_TRIALS_PER_COND,\n",
    "    'pac_surrogates': PAC_SURR_N,\n",
    "    'equalization_repeats': REPEATS_EQ,\n",
    "    'lag_grid_s': LAG_GRID.tolist(),\n",
    "    'exclude_lag_s': EXCLUDE_LAG_S,\n",
    "    'max_peak_to_peak': PEAK_TO_PEAK_THRESH,\n",
    "}\n",
    "\n",
    "print(f\"Session ID: {SESSION_ID}\")\n",
    "print(f\"Outputs \u2192 {SESSION_OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec706c5",
   "metadata": {},
   "source": [
    "### Resolve session file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def resolve_session_path(session_id: str, data_dir: Path, path_override: Path | None = None) -> Path:\n",
    "    '''Resolve an NWB file path using override, direct path, or globbing.'''\n",
    "    candidates = []\n",
    "    if path_override is not None:\n",
    "        candidates.append(Path(path_override).expanduser())\n",
    "    if session_id:\n",
    "        candidates.append(Path(session_id).expanduser())\n",
    "        candidates.append((data_dir / session_id).expanduser())\n",
    "    for candidate in candidates:\n",
    "        if candidate.suffix == '.nwb' and candidate.exists():\n",
    "            return candidate\n",
    "    if session_id:\n",
    "        matches = sorted(data_dir.rglob(f\"*{session_id}*.nwb\"))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    files = get_subject_files(data_dir)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No NWB files found under {data_dir}\")\n",
    "    if session_id:\n",
    "        print(f\"[warn] Could not find '{session_id}' under {data_dir}. Falling back to {files[0].name}\")\n",
    "    return files[0]\n",
    "\n",
    "\n",
    "SESSION_PATH = resolve_session_path(SESSION_ID, DATA_DIR, SESSION_PATH_OVERRIDE)\n",
    "print(f\"Using NWB file: {SESSION_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b8669",
   "metadata": {},
   "source": [
    "## 3. Load Data via Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06242c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = prepare_session_structures(\n",
    "    session_id=SESSION_ID,\n",
    "    session_path=SESSION_PATH,\n",
    "    conditions=CONDITIONS,\n",
    "    use_only_correct=USE_ONLY_CORRECT,\n",
    ")\n",
    "\n",
    "trial_table = session_data['trial_table']\n",
    "spike_times_by_unit = session_data['spike_times_by_unit']\n",
    "unit_meta = session_data['unit_meta']\n",
    "lfp_by_channel = session_data['lfp_by_channel']\n",
    "lfp_fs = session_data['lfp_fs']\n",
    "lfp_start_time = session_data['lfp_start_time']\n",
    "channel_meta = session_data['channel_meta']\n",
    "session_meta = session_data['session_meta']\n",
    "\n",
    "print(f\"Trials: {len(trial_table)} | Units: {len(spike_times_by_unit)} | Channels: {len(lfp_by_channel)} @ {lfp_fs:.1f} Hz\")\n",
    "trial_table.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689facbd",
   "metadata": {},
   "source": [
    "## 4. Preprocessing (CAR, bandpass, Hilbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f114b2",
   "metadata": {},
   "source": [
    "### Processing Details\n",
    "**LFP (vmPFC reference):** Drop channels flagged as bad (metadata `bad` column) or exceeding the configurable peak-to-peak bound; band-pass (3\u20137 Hz) with zero-phase filtering and extract instantaneous phase via Hilbert. Hippocampal LFPs undergo analogous filtering in the \u03b3 bands (default 70\u2013140 Hz, optional 30\u201355 Hz) with Hilbert amplitude envelopes for PAC.\n",
    "**Spikes (hipp units):** For each trial's maintenance window ([\u22120.5, +3.0] s), collect spikes from hippocampal single units. SFC samples theta phase at each spike time, then equalizes spike counts across conditions by random subsampling to the shared minimum (repeated 200\u00d7 to stabilize MVL estimates).\n",
    "**Metrics & surrogates:**\n",
    "- SFC uses the circular mean vector length (MVL = |(1/K)\u2211e^{i\u03d5}|). Surrogates jitter spikes within \u00b10.25 s of their trial to build \u03bc/\u03c3 for z-scoring.\n",
    "- ir-PAC uses amplitude-weighted MVL between vmPFC \u03b8 phase and hippocampal \u03b3 amplitude. Trials are shuffled (phase \u2194 amp) within condition to generate surrogate distributions; optional lag sweeps shift amp vs phase across \u2212150\u2026+150 ms (excluding |lag| <10\u201320 ms) before computing MVL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1805be",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_phase = compute_vmPFC_theta_phase(\n",
    "    lfp_by_channel=lfp_by_channel,\n",
    "    channel_meta=channel_meta,\n",
    "    sampling_rate=lfp_fs,\n",
    "    theta_band=THETA_BAND,\n",
    "    car_mode=CAR_MODE,\n",
    "    hilbert_pad_sec=1.0,\n",
    "    filter_order=4,\n",
    ")\n",
    "\n",
    "hipp_gamma_amp = compute_hipp_gamma_envelope(\n",
    "    lfp_by_channel=lfp_by_channel,\n",
    "    channel_meta=channel_meta,\n",
    "    sampling_rate=lfp_fs,\n",
    "    gamma_band=GAMMA_BAND,\n",
    "    hilbert_pad_sec=1.0,\n",
    "    filter_order=4,\n",
    ")\n",
    "\n",
    "print(f\"vmPFC \u03b8 channels: {len(theta_phase)}\")\n",
    "print(f\"Hipp \u03b3 channels: {len(hipp_gamma_amp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LFP Pair Formation (hipp \u03b3 channel \u00d7 vmPFC \u03b8 channel)\n",
    "Pairs enumerate hippocampal LFP channels supplying \u03b3 envelopes and vmPFC channels supplying \u03b8 phase. Channels must share a hemisphere when labels are available; otherwise they are paired globally.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "hipp_channels = channel_meta[channel_meta['area'].str.contains('hipp', case=False, na=False)].copy()\n",
    "vm_channels = channel_meta[channel_meta['area'].str.contains('vmpfc', case=False, na=False)].copy()\n",
    "hipp_channels['hemisphere'] = hipp_channels.get('hemisphere', 'unknown').fillna('unknown')\n",
    "vm_channels['hemisphere'] = vm_channels.get('hemisphere', 'unknown').fillna('unknown')\n",
    "\n",
    "pairs = []\n",
    "for hipp in hipp_channels.itertuples():\n",
    "    for vm in vm_channels.itertuples():\n",
    "        if hipp.hemisphere != 'unknown' and vm.hemisphere != 'unknown' and hipp.hemisphere != vm.hemisphere:\n",
    "            continue\n",
    "        pair_id = f\"hipp{hipp.chan_id}_vm{vm.chan_id}\"\n",
    "        pairs.append({\n",
    "            'pair_id': pair_id,\n",
    "            'unit_id': hipp.chan_id,\n",
    "            'hipp_chan_id': hipp.chan_id,\n",
    "            'unit_channel': hipp.chan_id,\n",
    "            'hipp_hemisphere': hipp.hemisphere,\n",
    "            'chan_id': vm.chan_id,\n",
    "            'vm_hemisphere': vm.hemisphere,\n",
    "        })\n",
    "\n",
    "pair_table = pd.DataFrame(pairs)\n",
    "print(f\"Candidate hipp\u00d7vmPFC channel pairs: {len(pair_table)}\")\n",
    "pair_table.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac228a",
   "metadata": {},
   "source": [
    "## 7. Hipp \u03b3 \u2194 vmPFC \u03b8 ir-PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_results = compute_irpac(\n",
    "    pair_table=pair_table,\n",
    "    trial_table=trial_table,\n",
    "    theta_phase=theta_phase,\n",
    "    gamma_envelope=hipp_gamma_amp,\n",
    "    lfp_fs=lfp_fs,\n",
    "    lfp_start_time=lfp_start_time,\n",
    "    epoch_analyze=EPOCH_ANALYZE,\n",
    "    conditions=CONDITIONS,\n",
    "    min_trials=MIN_TRIALS_PER_COND,\n",
    "    n_surrogates=PAC_SURR_N,\n",
    "    repeats_eq=REPEATS_EQ,\n",
    "    lag_grid_s=LAG_GRID,\n",
    "    exclude_lag_s=EXCLUDE_LAG_S,\n",
    ")\n",
    "\n",
    "pac_results['summary'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda265d4",
   "metadata": {},
   "source": [
    "## 8. Session-Level Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90656551",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_summary = run_session_stats(\n",
    "    sfc_results=None,\n",
    "    pac_results=pac_results,\n",
    "    conditions=CONDITIONS,\n",
    ")\n",
    "\n",
    "stats_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe72cb",
   "metadata": {},
   "source": [
    "## 9. QC & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pair_id = None\n",
    "summary_figs = plot_session_summary(\n",
    "    sfc_results=None,\n",
    "    pac_results=pac_results,\n",
    "    stats_summary=stats_summary,\n",
    "    conditions=CONDITIONS,\n",
    "    output_dir=SESSION_OUT_DIR,\n",
    "    dpi=150,\n",
    ")\n",
    "print(f\"Session summary figs: {summary_figs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e82d22",
   "metadata": {},
   "source": [
    "## 10. Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35076e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = save_session_outputs(\n",
    "    session_id=SESSION_ID,\n",
    "    output_dir=SESSION_OUT_DIR,\n",
    "    pair_table=None,\n",
    "    sfc_results=None,\n",
    "    pac_results=pac_results,\n",
    "    stats_summary=stats_summary,\n",
    "    analysis_params=ANALYSIS_PARAMS,\n",
    ")\n",
    "\n",
    "artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2198bc8",
   "metadata": {},
   "source": [
    "## 11. Appendix (runtime info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe52c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "runtime_info = {\n",
    "    'timestamp': datetime.utcnow().isoformat() + 'Z',\n",
    "    'python': sys.version,\n",
    "    'platform': platform.platform(),\n",
    "    'session_meta': session_meta,\n",
    "    'analysis_params': ANALYSIS_PARAMS,\n",
    "}\n",
    "\n",
    "print(json.dumps(runtime_info, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}