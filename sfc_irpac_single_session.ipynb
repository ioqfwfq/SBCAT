{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcf49a1",
   "metadata": {},
   "source": [
    "# Single-Session vmPFC θ SFC & Hipp γ↔vmPFC θ ir-PAC\n",
    "Working spec for a one-session pipeline that quantifies hippocampal spike-to-vmPFC theta phase locking and hippocampal gamma amplitude coupling to vmPFC theta phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137eea78",
   "metadata": {},
   "source": [
    "## Notebook Roadmap\n",
    "1. Configure session, storage paths, and analysis parameters.\n",
    "2. Load NWB session data through a common adapter that surfaces canonical tables/arrays.\n",
    "3. Preprocess LFPs (vmPFC θ phase, hippocampal γ amplitude) with optional CAR plus Hilbert transforms.\n",
    "4. Build hippocampal unit × vmPFC channel pairs (hemisphere-aware).\n",
    "5. Compute vmPFC θ spike-field coherence with spike-count balancing and jittered surrogate z-scores.\n",
    "6. Compute hippocampal γ ↔ vmPFC θ inter-regional PAC with trial-count balancing, shuffle surrogates, and optional lag sweeps.\n",
    "7. Aggregate per-pair metrics into session-level stats/visuals.\n",
    "8. Emit QC figures, tables, and summaries into a structured output directory.\n",
    "9. Append runtime/context metadata for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb3570",
   "metadata": {},
   "source": [
    "## Inputs & Interface Contract\n",
    "All downstream analysis blocks expect the following canonical objects (regardless of whether they were pulled directly from NWB):\n",
    "\n",
    "- **Events / Trials** – `trial_table`: DataFrame with `trial_id`, `condition_label`, `rt`, `maint_onset_time` (absolute seconds), `is_correct`, plus any auxiliary columns. Conditioning (e.g., `use_only_correct`, `conditions = ['L1','L3']`) is enforced during adapter loading.\n",
    "- **Spikes** – `spike_times_by_unit`: dict mapping `unit_id → np.ndarray` of spike times (seconds). `unit_meta`: DataFrame with `unit_id`, anatomical `area` labels (e.g., `hipp`) and `hemisphere` tags, ideally with the source electrode/channel index.\n",
    "- **LFP** – `lfp_by_channel`: dict `chan_id → np.ndarray`, along with `lfp_fs` (Hz), `lfp_start_time` (absolute seconds), and `channel_meta` describing each channel's area, hemisphere, bad-channel flags, and reference metadata. These support CAR/bipolar re-referencing before bandpass/Hilbert steps.\n",
    "- **Session meta** – lightweight dict containing `session_id`, patient/subject identifiers, session date, and the reference scheme (if available).\n",
    "\n",
    "The adapter defined in `nwb_analysis.cfc.prepare_session_structures` enforces this contract whether data are read from NWB, so the core analysis can focus on: (1) extracting [−0.5, +3.0] s windows around maintenance, (2) analyzing the [0, 2.5] s theta/gamma content, (3) equalizing spikes/trials per condition, and (4) computing surrogate-based z-scores (spike jitter for SFC, trial shuffle for PAC with optional lag sweeps).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb611e4",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca1eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from nwb_analysis import get_subject_files\n",
    "from nwb_analysis.cfc import (\n",
    "    prepare_session_structures,\n",
    "    compute_vmPFC_theta_phase,\n",
    "    compute_hipp_gamma_envelope,\n",
    "    compute_irpac,\n",
    "    run_session_stats,\n",
    "    plot_session_summary,\n",
    "    save_session_outputs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8b07f",
   "metadata": {},
   "source": [
    "## 2. Config & Session Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5755b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: SBCAT_Example_001\n",
      "Outputs → outputs/SBCAT_Example_001/sfc_irpac_single_session\n"
     ]
    }
   ],
   "source": [
    "# Session + storage config\n",
    "DATA_DIR = Path('/Users/jundazhu/SBCAT/000673')\n",
    "SESSION_ID = 'SBCAT_Example_001'  # can be partial stem or left as example\n",
    "SESSION_PATH_OVERRIDE = None      # Path('/absolute/path/to/sub-5_ses-1_ecephys+image.nwb') to skip globbing\n",
    "OUT_DIR = Path('outputs')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "USE_ONLY_CORRECT = True\n",
    "\n",
    "SESSION_OUT_DIR = OUT_DIR / SESSION_ID / 'sfc_irpac_single_session'\n",
    "SESSION_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONDITIONS = ['L1', 'L3']\n",
    "EPOCH_ANALYZE = (0.0, 2.5)       # s window used for analyses relative to maintenance onset\n",
    "EPOCH_LABEL = 'maintenance'\n",
    "THETA_BAND = (3.0, 7.0)\n",
    "PHASE_BAND_LABEL = 'theta'\n",
    "GAMMA_BAND = (30.0, 140.0)\n",
    "GAMMA_BAND_LABEL = 'gamma'\n",
    "CAR_MODE = 'hemisphere'\n",
    "MIN_TRIALS_PER_COND = 20\n",
    "PAC_SURR_N = 500\n",
    "LAG_GRID = np.arange(-0.150, 0.155, 0.005)  # seconds\n",
    "EXCLUDE_LAG_S = (0.010, 0.020)              # ignore central lags when reporting lag-swept PAC\n",
    "PEAK_TO_PEAK_THRESH = 3000.0  # µV; set to None to skip automatic rejection\n",
    "PAC_ALPHA = 0.05\n",
    "\n",
    "ANALYSIS_PARAMS = {\n",
    "    'conditions': CONDITIONS,\n",
    "    'epoch_analyze': EPOCH_ANALYZE,\n",
    "    'epoch_label': EPOCH_LABEL,\n",
    "    'theta_band': THETA_BAND,\n",
    "    'phase_band_label': PHASE_BAND_LABEL,\n",
    "    'gamma_band': GAMMA_BAND,\n",
    "    'gamma_band_label': GAMMA_BAND_LABEL,\n",
    "    'car_mode': CAR_MODE,\n",
    "    'min_trials': MIN_TRIALS_PER_COND,\n",
    "    'pac_surrogates': PAC_SURR_N,\n",
    "    'lag_grid_s': LAG_GRID.tolist(),\n",
    "    'exclude_lag_s': EXCLUDE_LAG_S,\n",
    "    'max_peak_to_peak': PEAK_TO_PEAK_THRESH,\n",
    "    'pac_alpha': PAC_ALPHA,\n",
    "}\n",
    "\n",
    "print(f\"Session ID: {SESSION_ID}\")\n",
    "print(f\"Outputs → {SESSION_OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec706c5",
   "metadata": {},
   "source": [
    "### Resolve session file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb7c6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] Could not find 'SBCAT_Example_001' under /Users/jundazhu/SBCAT/000673. Falling back to sub-1_ses-1_ecephys+image.nwb\n",
      "Using NWB file: /Users/jundazhu/SBCAT/000673/sub-1/sub-1_ses-1_ecephys+image.nwb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def resolve_session_path(session_id: str, data_dir: Path, path_override: Path | None = None) -> Path:\n",
    "    '''Resolve an NWB file path using override, direct path, or globbing.'''\n",
    "    candidates = []\n",
    "    if path_override is not None:\n",
    "        candidates.append(Path(path_override).expanduser())\n",
    "    if session_id:\n",
    "        candidates.append(Path(session_id).expanduser())\n",
    "        candidates.append((data_dir / session_id).expanduser())\n",
    "    for candidate in candidates:\n",
    "        if candidate.suffix == '.nwb' and candidate.exists():\n",
    "            return candidate\n",
    "    if session_id:\n",
    "        matches = sorted(data_dir.rglob(f\"*{session_id}*.nwb\"))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    files = get_subject_files(data_dir)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No NWB files found under {data_dir}\")\n",
    "    if session_id:\n",
    "        print(f\"[warn] Could not find '{session_id}' under {data_dir}. Falling back to {files[0].name}\")\n",
    "    return files[0]\n",
    "\n",
    "\n",
    "SESSION_PATH = resolve_session_path(SESSION_ID, DATA_DIR, SESSION_PATH_OVERRIDE)\n",
    "print(f\"Using NWB file: {SESSION_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b8669",
   "metadata": {},
   "source": [
    "## 3. Load Data via Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06242c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jundazhu/.pyenv/versions/3.10.17/lib/python3.10/site-packages/pynwb/ecephys.py:158: UserWarning: ElectricalSeries 'LFPs': The second dimension of data does not match the length of electrodes. Your data may be transposed.\n",
      "  warnings.warn(\"%s '%s': The second dimension of data does not match the length of electrodes. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials: 136 | Units: 46 | Channels: 70 @ 400.0 Hz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_label</th>\n",
       "      <th>rt</th>\n",
       "      <th>maint_onset_time</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>id</th>\n",
       "      <th>loads</th>\n",
       "      <th>PicIDs_Encoding1</th>\n",
       "      <th>PicIDs_Encoding2</th>\n",
       "      <th>PicIDs_Encoding3</th>\n",
       "      <th>PicIDs_Probe</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamps_Encoding1_end</th>\n",
       "      <th>timestamps_Encoding2</th>\n",
       "      <th>timestamps_Encoding2_end</th>\n",
       "      <th>timestamps_Encoding3</th>\n",
       "      <th>timestamps_Encoding3_end</th>\n",
       "      <th>timestamps_Maintenance</th>\n",
       "      <th>timestamps_Probe</th>\n",
       "      <th>timestamps_Response</th>\n",
       "      <th>response_accuracy</th>\n",
       "      <th>probe_in_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L3</td>\n",
       "      <td>1.660094</td>\n",
       "      <td>8.542684</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>201</td>\n",
       "      <td>101</td>\n",
       "      <td>501</td>\n",
       "      <td>501</td>\n",
       "      <td>...</td>\n",
       "      <td>4.203154</td>\n",
       "      <td>4.393779</td>\n",
       "      <td>6.401091</td>\n",
       "      <td>6.535497</td>\n",
       "      <td>8.542684</td>\n",
       "      <td>8.542684</td>\n",
       "      <td>11.746151</td>\n",
       "      <td>13.406245</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L3</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>21.168179</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "      <td>102</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>16.906399</td>\n",
       "      <td>16.947618</td>\n",
       "      <td>18.955961</td>\n",
       "      <td>19.159867</td>\n",
       "      <td>21.168179</td>\n",
       "      <td>21.168179</td>\n",
       "      <td>24.032771</td>\n",
       "      <td>25.030052</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L3</td>\n",
       "      <td>0.819468</td>\n",
       "      <td>32.644268</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>301</td>\n",
       "      <td>401</td>\n",
       "      <td>103</td>\n",
       "      <td>301</td>\n",
       "      <td>...</td>\n",
       "      <td>28.265895</td>\n",
       "      <td>28.458301</td>\n",
       "      <td>30.466706</td>\n",
       "      <td>30.635925</td>\n",
       "      <td>32.644268</td>\n",
       "      <td>32.644268</td>\n",
       "      <td>35.436236</td>\n",
       "      <td>36.255704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L1</td>\n",
       "      <td>0.848031</td>\n",
       "      <td>39.653265</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>...</td>\n",
       "      <td>39.653265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.653265</td>\n",
       "      <td>42.396920</td>\n",
       "      <td>43.244951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L3</td>\n",
       "      <td>2.271156</td>\n",
       "      <td>50.802136</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>402</td>\n",
       "      <td>203</td>\n",
       "      <td>504</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>46.591325</td>\n",
       "      <td>46.634856</td>\n",
       "      <td>48.643137</td>\n",
       "      <td>48.793824</td>\n",
       "      <td>50.802136</td>\n",
       "      <td>50.802136</td>\n",
       "      <td>53.367728</td>\n",
       "      <td>55.638884</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition_label        rt  maint_onset_time  is_correct  id  loads  \\\n",
       "0              L3  1.660094          8.542684        True   0      3   \n",
       "1              L3  0.997281         21.168179        True   1      3   \n",
       "2              L3  0.819468         32.644268        True   2      3   \n",
       "3              L1  0.848031         39.653265        True   3      1   \n",
       "4              L3  2.271156         50.802136        True   4      3   \n",
       "\n",
       "   PicIDs_Encoding1  PicIDs_Encoding2  PicIDs_Encoding3  PicIDs_Probe  ...  \\\n",
       "0               201               101               501           501  ...   \n",
       "1               202               102               502           502  ...   \n",
       "2               301               401               103           301  ...   \n",
       "3               503                 0                 0           503  ...   \n",
       "4               402               203               504           103  ...   \n",
       "\n",
       "   timestamps_Encoding1_end  timestamps_Encoding2  timestamps_Encoding2_end  \\\n",
       "0                  4.203154              4.393779                  6.401091   \n",
       "1                 16.906399             16.947618                 18.955961   \n",
       "2                 28.265895             28.458301                 30.466706   \n",
       "3                 39.653265              0.000000                  0.000000   \n",
       "4                 46.591325             46.634856                 48.643137   \n",
       "\n",
       "   timestamps_Encoding3  timestamps_Encoding3_end  timestamps_Maintenance  \\\n",
       "0              6.535497                  8.542684                8.542684   \n",
       "1             19.159867                 21.168179               21.168179   \n",
       "2             30.635925                 32.644268               32.644268   \n",
       "3              0.000000                  0.000000               39.653265   \n",
       "4             48.793824                 50.802136               50.802136   \n",
       "\n",
       "   timestamps_Probe  timestamps_Response  response_accuracy  probe_in_out  \n",
       "0         11.746151            13.406245                  1             1  \n",
       "1         24.032771            25.030052                  1             1  \n",
       "2         35.436236            36.255704                  1             1  \n",
       "3         42.396920            43.244951                  1             1  \n",
       "4         53.367728            55.638884                  1             0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_data = prepare_session_structures(\n",
    "    session_id=SESSION_ID,\n",
    "    session_path=SESSION_PATH,\n",
    "    conditions=CONDITIONS,\n",
    "    use_only_correct=USE_ONLY_CORRECT,\n",
    ")\n",
    "\n",
    "trial_table = session_data['trial_table']\n",
    "spike_times_by_unit = session_data['spike_times_by_unit']\n",
    "unit_meta = session_data['unit_meta']\n",
    "lfp_by_channel = session_data['lfp_by_channel']\n",
    "lfp_fs = session_data['lfp_fs']\n",
    "lfp_start_time = session_data['lfp_start_time']\n",
    "channel_meta = session_data['channel_meta']\n",
    "session_meta = session_data['session_meta']\n",
    "\n",
    "print(f\"Trials: {len(trial_table)} | Units: {len(spike_times_by_unit)} | Channels: {len(lfp_by_channel)} @ {lfp_fs:.1f} Hz\")\n",
    "trial_table.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689facbd",
   "metadata": {},
   "source": [
    "## 4. Preprocessing (CAR, bandpass, Hilbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f114b2",
   "metadata": {},
   "source": [
    "### Processing Details\n",
    "**LFP (vmPFC reference):** Drop channels flagged as bad (metadata `bad` column) or exceeding the configurable peak-to-peak bound; band-pass (3–7 Hz) with zero-phase filtering and extract instantaneous phase via Hilbert. Hippocampal LFPs undergo analogous filtering in the γ bands (default 70–140 Hz, optional 30–55 Hz) with Hilbert amplitude envelopes for PAC.\n",
    "**Spikes (hipp units):** For each trial's maintenance window ([−0.5, +3.0] s), collect spikes from hippocampal single units. SFC samples theta phase at each spike time, then equalizes spike counts across conditions by random subsampling to the shared minimum (repeated 200× to stabilize MVL estimates).\n",
    "**Metrics & surrogates:**\n",
    "- SFC uses the circular mean vector length (MVL = |(1/K)∑e^{iϕ}|). Surrogates jitter spikes within ±0.25 s of their trial to build μ/σ for z-scoring.\n",
    "- ir-PAC uses amplitude-weighted MVL between vmPFC θ phase and hippocampal γ amplitude. Trials are shuffled (phase ↔ amp) within condition to generate surrogate distributions; optional lag sweeps shift amp vs phase across −150…+150 ms (excluding |lag| <10–20 ms) before computing MVL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1805be",
   "metadata": {},
   "outputs": [],
   "source": "theta_phase = compute_vmPFC_theta_phase(\n    lfp_by_channel=lfp_by_channel,\n    channel_meta=channel_meta,\n    trial_table=trial_table,\n    sampling_rate=lfp_fs,\n    lfp_start_time=lfp_start_time,\n    epoch_analyze=EPOCH_ANALYZE,\n    theta_band=THETA_BAND,\n    car_mode=CAR_MODE,\n    trial_pad_sec=0.5,\n    filter_order=4,\n)\n\nhipp_gamma_amp = compute_hipp_gamma_envelope(\n    lfp_by_channel=lfp_by_channel,\n    channel_meta=channel_meta,\n    trial_table=trial_table,\n    sampling_rate=lfp_fs,\n    lfp_start_time=lfp_start_time,\n    epoch_analyze=EPOCH_ANALYZE,\n    gamma_band=GAMMA_BAND,\n    trial_pad_sec=0.5,\n    filter_order=4,\n)\n\nprint(f\"vmPFC θ channels: {len(theta_phase)}\")\nprint(f\"Hipp γ channels: {len(hipp_gamma_amp)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "9c7158af",
   "metadata": {},
   "source": [
    "## 5. LFP Pair Formation (hipp γ channel × vmPFC θ channel)\n",
    "Pairs enumerate hippocampal LFP channels supplying γ envelopes and vmPFC channels supplying θ phase. Channels must share a hemisphere when labels are available; otherwise they are paired globally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a869cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate hipp×vmPFC channel pairs: 98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>hipp_chan_id</th>\n",
       "      <th>unit_channel</th>\n",
       "      <th>hipp_hemisphere</th>\n",
       "      <th>chan_id</th>\n",
       "      <th>vm_hemisphere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hipp22_vm67</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>L</td>\n",
       "      <td>67</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hipp22_vm68</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>L</td>\n",
       "      <td>68</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hipp22_vm69</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>L</td>\n",
       "      <td>69</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hipp22_vm70</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>L</td>\n",
       "      <td>70</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hipp22_vm71</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>L</td>\n",
       "      <td>71</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id  unit_id  hipp_chan_id  unit_channel hipp_hemisphere  chan_id  \\\n",
       "0  hipp22_vm67       22            22            22               L       67   \n",
       "1  hipp22_vm68       22            22            22               L       68   \n",
       "2  hipp22_vm69       22            22            22               L       69   \n",
       "3  hipp22_vm70       22            22            22               L       70   \n",
       "4  hipp22_vm71       22            22            22               L       71   \n",
       "\n",
       "  vm_hemisphere  \n",
       "0             L  \n",
       "1             L  \n",
       "2             L  \n",
       "3             L  \n",
       "4             L  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hipp_channels = channel_meta[channel_meta['area'].str.contains('hipp', case=False, na=False)].copy()\n",
    "vm_channels = channel_meta[channel_meta['area'].str.contains('vmpfc', case=False, na=False)].copy()\n",
    "hipp_channels['hemisphere'] = hipp_channels.get('hemisphere', 'unknown').fillna('unknown')\n",
    "vm_channels['hemisphere'] = vm_channels.get('hemisphere', 'unknown').fillna('unknown')\n",
    "\n",
    "pairs = []\n",
    "for hipp in hipp_channels.itertuples():\n",
    "    for vm in vm_channels.itertuples():\n",
    "        if hipp.hemisphere != 'unknown' and vm.hemisphere != 'unknown' and hipp.hemisphere != vm.hemisphere:\n",
    "            continue\n",
    "        pair_id = f\"hipp{hipp.chan_id}_vm{vm.chan_id}\"\n",
    "        pairs.append({\n",
    "            'pair_id': pair_id,\n",
    "            'unit_id': hipp.chan_id,\n",
    "            'hipp_chan_id': hipp.chan_id,\n",
    "            'unit_channel': hipp.chan_id,\n",
    "            'hipp_hemisphere': hipp.hemisphere,\n",
    "            'chan_id': vm.chan_id,\n",
    "            'vm_hemisphere': vm.hemisphere,\n",
    "        })\n",
    "\n",
    "pair_table = pd.DataFrame(pairs)\n",
    "print(f\"Candidate hipp×vmPFC channel pairs: {len(pair_table)}\")\n",
    "pair_table.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac228a",
   "metadata": {},
   "source": [
    "## 7. Hipp γ ↔ vmPFC θ ir-PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906a48e",
   "metadata": {},
   "outputs": [],
   "source": "pac_results = compute_irpac(\n    pair_table=pair_table[:10],\n    trial_table=trial_table,\n    theta_phase=theta_phase,\n    gamma_envelope=hipp_gamma_amp,\n    lfp_fs=lfp_fs,\n    epoch_analyze=EPOCH_ANALYZE,\n    conditions=CONDITIONS,\n    min_trials=MIN_TRIALS_PER_COND,\n    n_surrogates=PAC_SURR_N,\n    lag_grid_s=None,\n    exclude_lag_s=EXCLUDE_LAG_S,\n    significance_alpha=PAC_ALPHA,\n    phase_band=THETA_BAND,\n    amp_band=GAMMA_BAND,\n    phase_band_label=PHASE_BAND_LABEL,\n    amp_band_label=GAMMA_BAND_LABEL,\n    epoch_label=EPOCH_LABEL,\n)\n\npac_results.head()"
  },
  {
   "cell_type": "markdown",
   "id": "eda265d4",
   "metadata": {},
   "source": [
    "## 8. Session-Level Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90656551",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_summary = run_session_stats(\n",
    "    sfc_results=None,\n",
    "    pac_results=pac_results,\n",
    "    conditions=CONDITIONS,\n",
    ")\n",
    "\n",
    "stats_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe72cb",
   "metadata": {},
   "source": [
    "## 9. QC & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pair_id = None\n",
    "summary_figs = plot_session_summary(\n",
    "    sfc_results=None,\n",
    "    pac_results=pac_results,\n",
    "    stats_summary=stats_summary,\n",
    "    conditions=CONDITIONS,\n",
    "    output_dir=SESSION_OUT_DIR,\n",
    "    dpi=150,\n",
    ")\n",
    "print(f\"Session summary figs: {summary_figs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e82d22",
   "metadata": {},
   "source": [
    "## 10. Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35076e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = save_session_outputs(\n",
    "    session_id=SESSION_ID,\n",
    "    session_path=SESSION_PATH,\n",
    "    output_dir=SESSION_OUT_DIR,\n",
    "    pair_table=None,\n",
    "    sfc_results=None,\n",
    "    pac_results=pac_results,\n",
    "    stats_summary=stats_summary,\n",
    "    analysis_params=ANALYSIS_PARAMS,\n",
    ")\n",
    "\n",
    "artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2198bc8",
   "metadata": {},
   "source": [
    "## 11. Appendix (runtime info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe52c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "runtime_info = {\n",
    "    'timestamp': datetime.utcnow().isoformat() + 'Z',\n",
    "    'python': sys.version,\n",
    "    'platform': platform.platform(),\n",
    "    'session_meta': session_meta,\n",
    "    'analysis_params': ANALYSIS_PARAMS,\n",
    "}\n",
    "\n",
    "print(json.dumps(runtime_info, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}